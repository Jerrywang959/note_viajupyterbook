

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>函数求极值 &#8212; Jerrynote</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../../../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../../../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/jupyter-sphinx.css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../../../_static/sphinx-book-theme.js"></script>
    <script type="text/javascript" src="../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../_static/doctools.js"></script>
    <script type="text/javascript" src="../../../_static/language_data.js"></script>
    <script type="text/javascript" src="../../../_static/togglebutton.js"></script>
    <script type="text/javascript" src="../../../_static/clipboard.min.js"></script>
    <script type="text/javascript" src="../../../_static/copybutton.js"></script>
    <script type="text/javascript" src="../../../_static/mystnb.js"></script>
    <script type="text/javascript" src="../../../_static/sphinx-book-theme.js"></script>
    <script type="text/javascript">var togglebuttonSelector = '.toggle, .secondtoggle, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script type="text/javascript" src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Surpervised Learning Intro" href="Supervised_learning.html" />
    <link rel="prev" title="矩阵相关知识" href="Math_base_matrix.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          

<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../../../index.html">
  
  <img src="../../../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Jerrynote</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  
  <ul class="nav sidenav_l1">
  <li class="">
    <a href="../../README.html">Introduction</a>
  </li>
  <li class="">
    <a href="../../Regular_Expression.html">Regular Expression</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">Julia_study</p>
</li>
  <li class="">
    <a href="../../julia_study/README.html">Julia学习笔记</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">R_study</p>
</li>
  <li class="">
    <a href="../../R_study/README.html">R语言的学习</a>
  </li>
<li class="navbar-special">
<p class="margin-caption">Course_study</p>
</li>
  <li class="active">
    <a href="../README.html">Introduction</a>
  <ul class="nav sidenav_l2">
    <li class="active">
      <a href="README.html">Introduction</a>
      <ul class="nav sidenav_l3">
      <li class="">
        <a href="Homework.html">2020-2-20</a>
      </li>
      <li class="">
        <a href="Math_base_matrix.html">矩阵相关知识</a>
      </li>
      <li class="active">
        <a href="">函数求极值</a>
      </li>
      <li class="">
        <a href="Supervised_learning.html">Surpervised Learning Intro</a>
      </li>
      <li class="">
        <a href="Linear_regression.html">线性回归</a>
      </li>
    </ul>
    </li>
    <li class="">
      <a href="../Game_Thoery/README.html">Intruduction</a>
    </li>
    <li class="">
      <a href="../Financial_Lecture/README.html">Financial_Lecture</a>
    </li>
    <li class="">
      <a href="../International_Finance/Exchanges.html">外汇的概念</a>
    </li>
    <li class="">
      <a href="../International_Finance/Exchanges_market.html">外汇市场</a>
    </li>
    <li class="">
      <a href="../Random_process/README.html">参考教材</a>
    </li>
    <li class="">
      <a href="../Times_series/README.html">课程介绍</a>
    </li>
  </ul>
  </li>
</ul>
</nav>
<p class="navbar_footer">Powered by <a href="https://jupyterbook.org">Jupyter Book</a></p>
</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse" data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu" aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation" title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        <div class="dropdown-buttons-trigger">
            <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i class="fas fa-download"></i></button>

            
            <div class="dropdown-buttons">
                <!-- ipynb file if we had a myst markdown file -->
                
                <!-- Download raw file -->
                <a class="dropdown-buttons" href="../../../_sources/content/Course_study/DM-ML/Math_base_opt.md.txt"><button type="button" class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip" data-placement="left">.md</button></a>
                <!-- Download PDF via print -->
                <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF" onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
            </div>
            
        </div>

        <!-- Edit this page -->
        

        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->
        

        
    </div>
    <div class="d-none d-md-block col-md-2 bd-toc show">
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#gradient-and-hessian" class="nav-link">Gradient and Hessian</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#gradient-descent" class="nav-link">Gradient Descent</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#eta-t" class="nav-link">\eta_t的选取</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#convergence-analysis" class="nav-link">Convergence Analysis</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#id2" class="nav-link">强凸性下的收敛性分析</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#newtons-method" class="nav-link">Newton’s Method</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#lagrangian-method" class="nav-link">Lagrangian Method</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#id3" class="nav-link">拉格朗日对偶函数</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h4">
            <a href="#id4" class="nav-link">性质</a>
        </li>
    
            </ul>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 col-xxl-7 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="id1">
<h1>函数求极值<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<div class="section" id="gradient-and-hessian">
<h2>Gradient and Hessian<a class="headerlink" href="#gradient-and-hessian" title="Permalink to this headline">¶</a></h2>
<p>函数<span class="math notranslate nohighlight">\(f:\mathbb{R}^d\rightarrow\mathbb{R}\)</span>的梯度为：
<span class="math notranslate nohighlight">\($
\nabla f=\left(\begin{array}{c}
\frac{\partial f}{\partial x_{1}} \\
\frac{\partial f}{\partial x_{2}} \\
\vdots \\
\frac{\partial f}{\partial x_{d}}
\end{array}\right)
$\)</span></p>
<p>函数<span class="math notranslate nohighlight">\(f:\mathbb{R}^d\rightarrow\mathbb{R}\)</span>的Hessian矩阵为
<span class="math notranslate nohighlight">\($
\nabla^{2} f=\left(\begin{array}{ccc}
\frac{\partial^{2} f}{\partial x_{1}^{2}} &amp; \cdots &amp; \frac{\partial^{2} f}{\partial x_{1} \partial x_{d}} \\
\vdots &amp; \ddots &amp; \vdots \\
\frac{\partial^{2} f}{\partial x_{d} \partial x_{1}} &amp; \cdots &amp; \frac{\partial^{2} f}{\partial x_{d}^{2}}
\end{array}\right)
$\)</span></p>
</div>
<div class="section" id="gradient-descent">
<h2>Gradient Descent<a class="headerlink" href="#gradient-descent" title="Permalink to this headline">¶</a></h2>
<p>梯度下降法</p>
<p><strong>一般迭代步骤</strong></p>
<p>目标函数 <span class="math notranslate nohighlight">\(\min\limits_x f(x)\)</span></p>
<p>迭代：<span class="math notranslate nohighlight">\(x_{t+1}=x_{t}-\eta_{t} \nabla f\left(x_{t}\right)\)</span></p>
<div class="section" id="eta-t">
<h3><span class="math notranslate nohighlight">\(\eta_t\)</span>的选取<a class="headerlink" href="#eta-t" title="Permalink to this headline">¶</a></h3>
<p><strong>精确线性搜索</strong></p>
<p><span class="math notranslate nohighlight">\(\eta_{t}=\arg \min _{\eta} f(x-\eta \nabla f(x))\)</span></p>
<p>往往这是不切实际的</p>
<p><strong>回溯线搜索</strong></p>
<p>我们令<span class="math notranslate nohighlight">\(\alpha\in(1,\frac{1}{2}],\beta\in(0,1)\)</span>，<span class="math notranslate nohighlight">\(\eta\)</span>从<span class="math notranslate nohighlight">\(\eta=1\)</span>出发，并不断迭代<span class="math notranslate nohighlight">\(\eta=\beta\eta\)</span>直到
<span class="math notranslate nohighlight">\($
f(x-\eta \nabla f(x)) \leq f(x)-\alpha \eta\|\nabla f(x)\|^{2}
$\)</span>
这种方法在实际操作中效果较佳</p>
</div>
</div>
<div class="section" id="convergence-analysis">
<h2>Convergence Analysis<a class="headerlink" href="#convergence-analysis" title="Permalink to this headline">¶</a></h2>
<p>收敛性分析</p>
<p>假设函数<span class="math notranslate nohighlight">\(f\)</span>是凸函数且可导，那么它是利普希茨连续的(Lipschitz continuous)：
<span class="math notranslate nohighlight">\($
\|\nabla f(x)-\nabla f(y)\|_{2} \leq L\|x-y\|_{2}
$\)</span>
<strong>定理</strong></p>
<p>固定步长<span class="math notranslate nohighlight">\(\eta\le\frac{1}{L}\)</span>的梯度下降法满足
<span class="math notranslate nohighlight">\($
f\left(x_{t}\right)-f^{*} \leq \frac{\left\|x_{0}-x^{*}\right\|_{2}^{2}}{2 t \eta}
$\)</span>
为了实现<span class="math notranslate nohighlight">\(f\left(x_{t}\right)-f^{*} \leq\epsilon\)</span>，我们需要<span class="math notranslate nohighlight">\(O(1 / \epsilon)\)</span>次的迭代</p>
<p>回溯线搜索的有着相同的收敛速度</p>
<div class="section" id="id2">
<h3>强凸性下的收敛性分析<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h3>
<p>假设<span class="math notranslate nohighlight">\(f\)</span>为强凸函数且<span class="math notranslate nohighlight">\(m\)</span>为常数</p>
<p><strong>定理</strong></p>
<p>固定步长<span class="math notranslate nohighlight">\(\eta\le2/(m+L)\)</span>或者回溯线搜索的梯度下降法满足
<span class="math notranslate nohighlight">\($
f\left(x_{t}\right)-f^{*} \leq c^{t} \frac{L}{2}\left\|x_{0}-x^{*}\right\|_{2}^{2}
$\)</span>
此处<span class="math notranslate nohighlight">\(0&lt;c&lt;1\)</span></p>
<p>为了实现<span class="math notranslate nohighlight">\(f\left(x_{t}\right)-f^{*} \leq\epsilon\)</span>，我们需要<span class="math notranslate nohighlight">\(O(\log(1 / \epsilon))\)</span>次的迭代</p>
<p>这被称为线性收敛</p>
</div>
</div>
<div class="section" id="newtons-method">
<h2>Newton’s Method<a class="headerlink" href="#newtons-method" title="Permalink to this headline">¶</a></h2>
<p>牛顿法求解最值问题</p>
<p><strong>思路：从一个点出发，寻找它附近比它更接近导数为0的点的点</strong></p>
<p>任意一个函数<span class="math notranslate nohighlight">\(f(x)\)</span>可以写成如下的形式：
<span class="math notranslate nohighlight">\($
f(x) \approx f(x-x_k)+\nabla f(x-x_k)^{\top} (x-x_k)+\frac{1}{2} (x-x_k)^{\top} \nabla^{2} f(x-x_k) (x-x_k)
$\)</span>
其中，<span class="math notranslate nohighlight">\(x\)</span>为<span class="math notranslate nohighlight">\(x_k\)</span>附近的一个点。如果令<span class="math notranslate nohighlight">\(\approx\)</span>变成<span class="math notranslate nohighlight">\(=\)</span>，对上式的右边对<span class="math notranslate nohighlight">\(x\)</span>求导数，并令其为0（即，使<span class="math notranslate nohighlight">\(f\prime(x)=0\)</span>)，则有
<span class="math notranslate nohighlight">\($
\nabla f(x_k) + \nabla^{2} f(x_k) (x-x_k)=0
$\)</span></p>
<p>整理得到</p>
<div class="math notranslate nohighlight">
\[
x=x_k-\left[\nabla^{2} f(x_k)\right]^{-1} \nabla f(x_k)
\]</div>
<p>这个式子表明，在近似情况下，从<span class="math notranslate nohighlight">\(x_k\)</span>来看，<span class="math notranslate nohighlight">\(x\)</span>是使得<span class="math notranslate nohighlight">\(f\prime(x)\)</span>为<span class="math notranslate nohighlight">\(0\)</span>的点，即最值点。</p>
<p>那么我们可以认为，在不近似的情况下<span class="math notranslate nohighlight">\(x\)</span>是比<span class="math notranslate nohighlight">\(x_k\)</span>更加接近导数为0的点的点。</p>
<p>因此我们可以得到如下的迭代过程
<span class="math notranslate nohighlight">\($
x_{k+1}=x_k-\left[\nabla^{2} f(x_k)\right]^{-1} \nabla f(x_k)
$\)</span>
牛顿法的一般迭代步骤如下：</p>
<ol class="simple">
<li><p>给定终止误差值<span class="math notranslate nohighlight">\(0\leq\epsilon\ll1\)</span>，初始点<span class="math notranslate nohighlight">\(x\in R_n\)</span>，<span class="math notranslate nohighlight">\(k=0\)</span></p></li>
<li><p>计算<span class="math notranslate nohighlight">\(g_{k}=\nabla f\left(x_{k}\right)\)</span>，若<span class="math notranslate nohighlight">\(\left\|g_{k}\right\| \leq \varepsilon\)</span>，则终止迭代</p></li>
<li><p>计算<span class="math notranslate nohighlight">\(G_{k}=\nabla^2 f\left(x_{k}\right)\)</span>，并求解线性方程组得解<span class="math notranslate nohighlight">\(d_{k}: G_{k} d=-g_{k}\)</span></p></li>
<li><p>令<span class="math notranslate nohighlight">\(x_{k+1}=x_{k}+d_{k}, k=k+1\)</span>，并转2。</p></li>
</ol>
<p>也可以给定步长迭代。</p>
<p><strong>牛顿法的条件</strong></p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(f\)</span>是强凸函数</p></li>
<li><p><span class="math notranslate nohighlight">\(\nabla f(x),\nabla^2 f(x)\)</span>都是利普希茨连续的</p></li>
</ol>
<p><strong>牛顿法的性质</strong></p>
<ol class="simple">
<li><p>二次收敛：收敛比率为<span class="math notranslate nohighlight">\(O(\log(\log(1 / \epsilon)))\)</span></p></li>
<li><p>局部二次收敛:我们只保证经过若干步k后的二次收敛。</p></li>
<li><p>缺点：计算Hessian矩阵的逆矩阵比较耗费资源，后来出现了Quasi-Newton, Approximate Newton</p></li>
</ol>
</div>
<div class="section" id="lagrangian-method">
<h2>Lagrangian Method<a class="headerlink" href="#lagrangian-method" title="Permalink to this headline">¶</a></h2>
<p>从一个优化问题出发
<span class="math notranslate nohighlight">\($
\begin{array}{l}
\min\limits_{x} f(x) \\
\text { s.t. } g_{i}(x) \leq 0, i=1,2, \ldots, m \\
\quad h_{j}(x)=0, j=1,2, \ldots, n
\end{array}
$\)</span>
我们定义拉格朗日函数为
<span class="math notranslate nohighlight">\($
L(x, u, v)=f(x)+\sum_{i=1}^{m} u_{i} g_{i}(x)+\sum_{j=1}^{n} v_{j} h_{j}(x) \qquad ,u_i\ge0
$\)</span>
（本质上是把约束条件转化为惩罚函数加入目标：这是一个最小化的目标，令<span class="math notranslate nohighlight">\(u_i\ge0\)</span>意味着要想最小化<span class="math notranslate nohighlight">\(L\)</span>，<span class="math notranslate nohighlight">\(g_i(x)\)</span>必须越小越好）</p>
<p>$\forall u\ge0 ,v <span class="math notranslate nohighlight">\(和可行的\)</span>x<span class="math notranslate nohighlight">\(，我们有（因为\)</span>L<span class="math notranslate nohighlight">\(函数的定义域比\)</span>f<span class="math notranslate nohighlight">\(函数的定义域更大，或者说：约束更小）
$\)</span>
L(x, u, v) \leq f(x)
$$</p>
<div class="section" id="id3">
<h3>拉格朗日对偶函数<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<p><span class="math notranslate nohighlight">\(C\)</span>表示原始的可行解，<span class="math notranslate nohighlight">\(f^*\)</span>表示原始的最优解，在所有的<span class="math notranslate nohighlight">\(x\)</span>上最小化<span class="math notranslate nohighlight">\(L(x,u,v)\)</span>会得到<span class="math notranslate nohighlight">\(f^*\)</span>的更小的边界，<span class="math notranslate nohighlight">\(\forall u\ge0,v\)</span>，即
<span class="math notranslate nohighlight">\($
f^{*} \geq \min _{x \in C} L(x, u, v) \geq \min _{x} L(x, u, v)=g(u, v)
$\)</span>
对偶函数的形式为
<span class="math notranslate nohighlight">\($
g(u, v)=\min _{x} L(x, u, v)
$\)</span>
对于初始的问题，拉格朗日对偶问题为
<span class="math notranslate nohighlight">\($
\begin{array}{l}
\max\limits _{u, v} g(u, v) \\
\text {s.t. } u \geq 0
\end{array}
$\)</span></p>
<div class="section" id="id4">
<h4>性质<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h4>
<ol class="simple">
<li><p>弱对偶性
<span class="math notranslate nohighlight">\($
f^*\ge g^*
$\)</span></p></li>
<li><p>对偶问题是一个凸优化问题，即使原优化问题并不是凸的</p></li>
</ol>
<div class="math notranslate nohighlight">
\[
g(u, v)=\min _{x}\left\{f(x)+\sum_{i=1}^{m} u_{i} g_{i}(x)+\sum_{j=1}^{n} v_{j} h_{j}(x)\right\}
\]</div>
<ol class="simple">
<li><p>函数<span class="math notranslate nohighlight">\(g(u,v)\)</span>是凹的</p></li>
</ol>
<p><strong>强对偶性</strong></p>
<p>在某些情况下（原问题是凸的），我们可以观察到<span class="math notranslate nohighlight">\(f^*=g^*\)</span>，这被称为强对偶性</p>
<p><strong>斯莱特条件</strong>（Slater’s condition，充分条件）</p>
<p>如果原问题是凸优化问题，且至少存在一个严格可行的<span class="math notranslate nohighlight">\(x\)</span>，满足
<span class="math notranslate nohighlight">\($
g_{1}(x)&lt;0, \ldots, g_{m}(x)&lt;0 \text { and } h_{1}(x)=\ldots h_{n}(x)=0
$\)</span>
那么强对偶性满足。</p>
<p><img alt="UTOOLS1587872480002.png" src="https://mypictuchuang.oss-cn-shenzhen.aliyuncs.com/UTOOLS1587872480002.png" /></p>
</div>
</div>
</div>
</div>
<div class="section" id="id5">
<h1>参考文献<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h1>
<ol class="simple">
<li><p><a class="reference external" href="https://zhuanlan.zhihu.com/p/37588590">理解牛顿法</a></p></li>
<li><p><a class="reference external" href="https://blog.csdn.net/google19890102/article/details/41087931">优化算法——牛顿法(Newton Method)</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Newton%27s_method">Newton’s method</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Backtracking_line_search">Backtracking line search</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Line_search">Line search</a></p></li>
</ol>
</div>


              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="Math_base_matrix.html" title="previous page">矩阵相关知识</a>
    <a class='right-next' id="next-link" href="Supervised_learning.html" title="next page">Surpervised Learning Intro</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
  <div class="container">
    <p>
          &copy; Copyright 2020.<br/>
        Created using <a href="http://sphinx-doc.org/">Sphinx</a> 2.2.0.<br/>
    </p>
  </div>
</footer>
</main>


      </div>
    </div>

    <script src="../../../_static/js/index.js"></script>
    
  </body>
</html>